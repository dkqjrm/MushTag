{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_xhlhJicnXu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import ViltProcessor, ViltForImagesAndTextClassification, ViltConfig, ViltModel, AdamW\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import ast\n",
    "import shutil\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbIVyPMsS_7T",
    "outputId": "ecb5348f-b3d6-4488-9c2d-0463820d71d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb710234bb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(97)\n",
    "torch.random.manual_seed(97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKGN_mHAAbuR"
   },
   "outputs": [],
   "source": [
    "def scoring(pred, target, topk):\n",
    "    pred = torch.argsort(pred, dim=1, descending=True)\n",
    "    pred = pred.cpu().detach().numpy()  # [batch_size, hashtag_vocab_size]\n",
    "    target = target  # [batch_size, hashtag_vocab_size]\n",
    "    tag_label = []\n",
    "    for this_data in target:\n",
    "        tag_label.append([])\n",
    "        for idx, each_tag in enumerate(this_data):\n",
    "            if each_tag != 0:\n",
    "                tag_label[-1].append(idx)\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    print(pred)\n",
    "    for i in range(len(pred)):\n",
    "        this_precision = 0\n",
    "        this_recall = 0\n",
    "        this_f1 = 0\n",
    "        if (len(tag_label[i]) != 0):\n",
    "            for j in range(topk):\n",
    "                if pred[i][j] in tag_label[i]:\n",
    "                    this_precision += 1\n",
    "            for j in range(len(tag_label[i])):\n",
    "                if tag_label[i][j] in pred[i][:topk]:\n",
    "                    this_recall += 1\n",
    "            this_precision /= topk\n",
    "            this_recall /= len(tag_label[i])\n",
    "            if this_precision != 0 and this_recall != 0:\n",
    "                this_f1 = 2 * (this_precision * this_recall) / (this_precision + this_recall)\n",
    "        precision.append(this_precision)\n",
    "        recall.append(this_recall)\n",
    "        f1.append(this_f1)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1652110810279,
     "user": {
      "displayName": "원현식",
      "userId": "13680763307369207869"
     },
     "user_tz": -540
    },
    "id": "UkwiWRzQfbST",
    "outputId": "99387177-d3bc-4bd8-8811-a080504b00f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vP6NF3_NS_7U"
   },
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, pretrained_model='dandelin/vilt-b32-mlm'):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.vilt = ViltModel.from_pretrained(pretrained_model)\n",
    "        self.linear = nn.Linear(768,1000)\n",
    "        self.norm = nn.LayerNorm(1000)\n",
    "        self.acti = nn.GELU()\n",
    "        self.linear2= nn.Linear(1000,2000)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        pixel_values=None,\n",
    "        pixel_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        image_embeds=None,\n",
    "        image_token_type_idx=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        pooler_output = self.vilt(input_ids, token_type_ids, attention_mask, pixel_values, pixel_mask).pooler_output\n",
    "        predict = self.linear(pooler_output)\n",
    "        predict = self.norm(predict)\n",
    "        predict = self.acti(predict)\n",
    "        predict = self.linear2(predict)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9uhgAR_S_7V",
    "outputId": "e646de26-2fcb-4995-c962-7d6942bfbdc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dandelin/vilt-b32-mlm were not used when initializing ViltModel: ['mlm_score.bias', 'mlm_score.transform.LayerNorm.bias', 'mlm_score.transform.dense.bias', 'mlm_score.decoder.weight', 'mlm_score.transform.LayerNorm.weight', 'mlm_score.transform.dense.weight']\n",
      "- This IS expected if you are initializing ViltModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViltModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel()\n",
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-mlm\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48M-1-Y7S_7W"
   },
   "outputs": [],
   "source": [
    "class SSTDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-mlm\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,str(self.df.iloc[idx]['Unnamed: 0']) + '.jpg')\n",
    "        image = Image.open(img_name)\n",
    "#         text = str(self.df.iloc[idx]['after_contents']) # without location information\n",
    "        text = str(self.df.iloc[idx]['concat_category_location']) # with location information\n",
    "        label = ast.literal_eval(self.df.iloc[idx]['new_hashtags_2000_onehot'])\n",
    "        labels = ast.literal_eval(self.df.iloc[idx]['new_hashtags_2000_onehots'])\n",
    "        process_output = self.processor(image, text,truncation=True, padding = 'max_length', return_tensors=\"pt\")\n",
    "        for k,v in process_output.items():\n",
    "            process_output[k] = v.squeeze()\n",
    "        process_output['labels'] = labels\n",
    "        process_output['label'] = label\n",
    "        \n",
    "        return process_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIK4aT9mS_7W"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    pixel_values = [item['pixel_values'] for item in batch]\n",
    "    attention_mask = [item['attention_mask'] for item in batch]\n",
    "    token_type_ids = [item['token_type_ids'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "    label = [item['label'] for item in batch]\n",
    "\n",
    "    # create padded pixel values and corresponding pixel mask\n",
    "    encoding = processor.feature_extractor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n",
    "\n",
    "    # create new batch\n",
    "    batch = {}\n",
    "    batch['input_ids'] = torch.stack(input_ids)\n",
    "    batch['attention_mask'] = torch.stack(attention_mask)\n",
    "    batch['token_type_ids'] = torch.stack(token_type_ids)\n",
    "    batch['pixel_values'] = encoding['pixel_values']\n",
    "    batch['pixel_mask'] = encoding['pixel_mask']\n",
    "    batch['labels'] = torch.LongTensor(labels)\n",
    "    batch['label'] = torch.LongTensor(label)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kv0WulRHS_7W"
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "dataset = SSTDataset('post_dataset.csv','./drop_image')\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_val_size = len(dataset) - train_size\n",
    "train_dataset, test_val_dataset = torch.utils.data.random_split(dataset, [train_size, test_val_size])\n",
    "val_size = int(0.5 * len(test_val_dataset))\n",
    "test_size = len(test_val_dataset) - val_size\n",
    "val_dataset, test_dataset = torch.utils.data.random_split(test_val_dataset, [val_size,test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size,collate_fn=collate_fn, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, collate_fn=collate_fn, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size,collate_fn=collate_fn, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfwxF60CYEk4"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, model_save_path, filename):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, os.path.join(model_save_path, 'model_best.pth.tar'))\n",
    "\n",
    "save_path = './saved_model/'\n",
    "save_path = os.path.join(save_path,\n",
    "                             time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(time.time())))\n",
    "writer = SummaryWriter(log_dir=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roiziazES_7Y"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652110863043,
     "user": {
      "displayName": "원현식",
      "userId": "13680763307369207869"
     },
     "user_tz": -540
    },
    "id": "QKZw7EOt4vg5",
    "outputId": "2925cab0-c204-435a-81aa-215289cbeb7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.venv/torch1.12.0-py3.9-cuda11.6/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# HyperParameter\n",
    "\n",
    "lr = 0.0001\n",
    "weight_decay = 0.01\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "threshold = 5\n",
    "topk = 5\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda = lambda epoch: 0.95 ** epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRo259-PS_7Y"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path,\"config.txt\"),\"w\") as f:\n",
    "    f.write(\"batch_size = \" + str(batch_size)+\"\\n\")\n",
    "    f.write(\"learning_rate = \" + str(lr)+ \"\\n\")\n",
    "    f.write(\"threshold = \" + str(threshold)+ \"\\n\")\n",
    "    f.write(\"weight_decay = \" + str(weight_decay)+ \"\\n\")\n",
    "    f.write(\"optim = \" + str(optimizer) +\"\\n\")\n",
    "    f.write(\"topk = \" + str(topk)+ \"\\n\")\n",
    "    f.write(\"Location = True \" + \"\\n\")\n",
    "    f.write(\"hashtag = 2000 \\n\")\n",
    "    f.write(str(criterion)+'\\n')\n",
    "    f.write(\"Model 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFbJOBNwZB2w"
   },
   "outputs": [],
   "source": [
    "global_steps = 0\n",
    "epoch = 0\n",
    "max_f1 = 0\n",
    "stop_cnt = 0\n",
    "while True:\n",
    "    epoch += 1\n",
    "    model.train()\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    train_loss = 0\n",
    "    cnt = 0\n",
    "    for batch in tqdm(train_loader, total=len(train_loader)):\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        logits = model(batch['input_ids'],batch['attention_mask'],batch['token_type_ids'],batch['pixel_values'],batch['pixel_mask'])\n",
    "        label = batch['label'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        print(logits)\n",
    "        loss = criterion(logits,label.float())\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        cnt += len(label)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_p, batch_r, batch_f1 = scoring(logits, labels, topk) # topk\n",
    "        precision.extend(batch_p)\n",
    "        recall.extend(batch_r)\n",
    "        f1.extend(batch_f1)\n",
    "\n",
    "        writer.add_scalar(tag='batch_precision',\n",
    "                                scalar_value=sum(batch_p)/len(batch_p),\n",
    "                                global_step=global_steps)\n",
    "        writer.add_scalar(tag='batch_recall',\n",
    "                            scalar_value=sum(batch_r) / len(batch_r),\n",
    "                            global_step=global_steps)\n",
    "        writer.add_scalar(tag='batch_f1',\n",
    "                            scalar_value=sum(batch_f1) / len(batch_f1),\n",
    "                            global_step=global_steps)\n",
    "        writer.add_scalar(tag='batch_loss',\n",
    "                            scalar_value=loss.item(),\n",
    "                            global_step=global_steps)\n",
    "        global_steps += 1\n",
    "\n",
    "    writer.add_scalar(tag='train_precision',\n",
    "                            scalar_value=sum(precision) / len(precision),\n",
    "                            global_step=epoch)\n",
    "    writer.add_scalar(tag='train_recall',\n",
    "                        scalar_value=sum(recall) / len(recall),\n",
    "                        global_step=epoch)\n",
    "    writer.add_scalar(tag='train_f1',\n",
    "                        scalar_value=sum(f1) / len(f1),\n",
    "                        global_step=epoch)\n",
    "    writer.add_scalar(tag='train_loss',\n",
    "                        scalar_value=train_loss / cnt,\n",
    "                        global_step=epoch)\n",
    "    scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    val_loss = 0\n",
    "    cnt = 0\n",
    "    for batch in tqdm(val_loader, total=len(val_loader)):\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        label = batch['label'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(batch['input_ids'],batch['attention_mask'],batch['token_type_ids'],batch['pixel_values'],batch['pixel_mask'])\n",
    "        print(logits)\n",
    "        loss = criterion(logits,label.float())\n",
    "        val_loss += loss.item()\n",
    "        cnt += len(label)\n",
    "        batch_p, batch_r, batch_f1 = scoring(logits, labels, topk) #topk\n",
    "        precision.extend(batch_p)\n",
    "        recall.extend(batch_r)\n",
    "        f1.extend(batch_f1)\n",
    "    val_p = sum(precision)/len(precision)\n",
    "    val_r = sum(recall) / len(recall)\n",
    "    val_f1 = sum(f1) / len(f1)\n",
    "    writer.add_scalar(tag='val_precision',\n",
    "                        scalar_value=val_p,\n",
    "                        global_step=epoch)\n",
    "    writer.add_scalar(tag='val_recall',\n",
    "                        scalar_value=val_r,\n",
    "                        global_step=epoch)\n",
    "    writer.add_scalar(tag='val_f1',\n",
    "                        scalar_value=val_f1,\n",
    "                        global_step=epoch)\n",
    "    writer.add_scalar(tag='val_loss',\n",
    "                        scalar_value=val_loss / cnt,\n",
    "                        global_step=epoch)\n",
    "\n",
    "    if val_f1 > max_f1:\n",
    "        max_f1 = val_f1\n",
    "        stop_cnt = 0\n",
    "        is_best = True\n",
    "    else:\n",
    "        stop_cnt += 1\n",
    "        is_best = False\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'precision': val_p,\n",
    "        'recall': val_r,\n",
    "        'f1-score': val_f1,\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }, is_best, save_path, os.path.join(save_path, 'epoch' + str(epoch) + '.pth.tar'))\n",
    "\n",
    "    if stop_cnt > threshold: # threshold\n",
    "        print(\"Training finished.\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Re-Hash.ipynb",
   "provenance": [
    {
     "file_id": "1j1wZ2eUa-D_vhrKHOtMbjrmBAgLtzfK_",
     "timestamp": 1652099425990
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
